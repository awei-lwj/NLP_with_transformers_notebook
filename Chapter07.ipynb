{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1f3YkjJLJV9"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import get_dataset_config_names\n",
        "domains = get_dataset_config_names(\"subjqa\")\n",
        "\n",
        "domains\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "subjqa = load_dataset(\"subjqa\", name=\"electronics\")\n"
      ],
      "metadata": {
        "id": "20mJK-C0L4Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subjqa[\"train\"][\"answers\"][1])"
      ],
      "metadata": {
        "id": "D7LQLhfpMdTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\n",
        "for split, df in dfs.items():\n",
        "\tprint(f\"Number of questions in {split}: {df['id'].nunique()}\")"
      ],
      "metadata": {
        "id": "GBLNsoa6NFq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_cols = [\"title\", \"question\", \"answers.text\", \"answers.answer_start\", \"context\"]\n",
        "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
        "sample_df"
      ],
      "metadata": {
        "id": "oZagXcvYQoY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\n",
        "end_idx = start_idx + len(sample_df[\"answers.text\"].iloc[0][0])\n",
        "sample_df[\"context\"].iloc[0][start_idx:end_idx]\n"
      ],
      "metadata": {
        "id": "qKcfQNs5RXzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "counts = {}\n",
        "question_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n",
        "for q in question_types:\n",
        "\tcounts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()\n",
        "\n",
        "pd.Series(counts).sort_values().plot.barh()\n",
        "plt.title(\"Frequency of Question Types\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rM4iadr7SEah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question_type in [\"How\", \"What\", \"Is\"]:\n",
        "\tfor question in ( dfs[\"train\"][dfs[\"train\"].question.str.startswith(question_type)] .sample(n=3, random_state=42)['question']):\n",
        "\t\tprint(question)"
      ],
      "metadata": {
        "id": "CXdt87nwTaa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "aVINRUc5WROV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How much music can this hold?\"\n",
        "context = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\ file size.\"\"\"\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "id": "ceRL8AwzWcQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "id": "P1rWMsYFW3Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
      ],
      "metadata": {
        "id": "C1GPTmORXH54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
        "with torch.no_grad():\n",
        "\toutputs = model(**inputs)\n",
        "\tprint(outputs)"
      ],
      "metadata": {
        "id": "YpzlIM5YXc1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits"
      ],
      "metadata": {
        "id": "AHf78dKBXrpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input IDs shape: {inputs.input_ids.size()}\")\n",
        "print(f\"Start logits shape: {start_logits.size()}\")\n",
        "print(f\"End logits shape: {end_logits.size()}\")\n"
      ],
      "metadata": {
        "id": "3_QJvPc6X-d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "start_idx = torch.argmax(start_logits)\n",
        "end_idx = torch.argmax(end_logits) + 1\n",
        "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
        "answer = tokenizer.decode(answer_span)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n"
      ],
      "metadata": {
        "id": "DydQBf42Ydia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "pipe(question=question, context=context, topk=3)\n",
        "\n",
        "pipe(question=\"Why is there no data?\", context=context, handle_impossible_answer=True)"
      ],
      "metadata": {
        "id": "bxNplZMYZFez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "超越抽取式QA直接生成而非提取\n"
      ],
      "metadata": {
        "id": "OO75LiGtoNty"
      }
    }
  ]
}