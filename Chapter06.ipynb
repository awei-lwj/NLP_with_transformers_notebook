{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhMsoY5vjyr_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "try:\n",
        "  dataset = load_dataset(\"cnn_dailymail\",\"3.0.0\")\n",
        "  print(f\"Features: {dataset['train'].column_names}\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = dataset[\"train\"][1]\n",
        "print(f\"\"\" Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}): \"\"\")\n",
        "print(sample[\"article\"][:500])\n",
        "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
        "print(sample[\"highlights\"])"
      ],
      "metadata": {
        "id": "BPB8lohOnync"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
        "# We'll collect the generated summaries of each model in a dictionary\n",
        "summaries = {}"
      ],
      "metadata": {
        "id": "QvGGzFd0n0I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uV3jk6LBnzaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
        "sent_tokenize(string)"
      ],
      "metadata": {
        "id": "dMfSctfgp9qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def three_sentence_summary(text):\n",
        "\treturn \"\\n\".join(sent_tokenize(text)[:3])\n",
        "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
      ],
      "metadata": {
        "id": "LIW9UipyqP7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "set_seed(42)\n",
        "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
        "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
        "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
        "\n",
        "summaries[\"gpt2\"] = \"\\n\".join( sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
      ],
      "metadata": {
        "id": "5sTBnk5zqq6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))\n"
      ],
      "metadata": {
        "id": "2bI9rJJF262M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")\n"
      ],
      "metadata": {
        "id": "tYQVBI8a6nBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GROUND TRUTH\")\n",
        "print(dataset[\"train\"][1][\"highlights\"])\n",
        "print(\"\")\n",
        "for model_name in summaries:\n",
        "\tprint(model_name.upper())\n",
        "\tprint(summaries[model_name])\n",
        "\tprint(\"\")"
      ],
      "metadata": {
        "id": "fc9nl_bP7Bvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ER7KY_8k-moD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu\n",
        "from datasets import load_metric\n",
        "bleu_metric = load_metric(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "FzVEsrmB-nJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "bleu_metric.add( prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
        "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
        "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
        "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n"
      ],
      "metadata": {
        "id": "baX1Rslt_-u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n",
        "rouge_metric = load_metric(\"rouge\")\n"
      ],
      "metadata": {
        "id": "Bx6VsoydDnRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference = dataset[\"train\"][1][\"highlights\"]\n",
        "records = []\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "for model_name in summaries:\n",
        "\trouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
        "\tscore = rouge_metric.compute()\n",
        "\trouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "\trecords.append(rouge_dict)\n",
        "pd.DataFrame.from_records(records, index=summaries.keys())"
      ],
      "metadata": {
        "id": "eYnDiOUcDyoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_summaries_baseline(dataset, metric, column_text=\"article\", \t\t\tcolumn_summary=\"highlights\"):\n",
        "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "    metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
        "    score = metric.compute()\n",
        "    return score\n"
      ],
      "metadata": {
        "id": "ilts-VHzEzyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T\n"
      ],
      "metadata": {
        "id": "iBIvmnBsFPol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "def chunks(list_of_elements, batch_size):\n",
        "\t\"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "\tfor i in range(0, len(list_of_elements), batch_size):\n",
        "\t  yield list_of_elements[i : i + batch_size]\n",
        "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"highlights\"):\n",
        "\tarticle_batches = list(chunks(dataset[column_text], batch_size))\n",
        "\ttarget_batches = list(chunks(dataset[column_summary], batch_size))\n",
        "\tfor article_batch, target_batch in tqdm( zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\t\tinputs = tokenizer(article_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\t\tsummaries = model.generate(input_ids=inputs[\"input_ids\"].to(device), attention_mask=inputs[\"attention_mask\"].to(device), length_penalty=0.8, num_beams=8, max_length=128)\n",
        "\t\tdecoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in summaries]\n",
        "\t\tdecoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "\t\tmetric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\tscore = metric.compute()\n",
        "\treturn score\n"
      ],
      "metadata": {
        "id": "JSnh-B4SGxZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}